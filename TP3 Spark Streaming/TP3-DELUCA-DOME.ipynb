{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il2wKA8wEWu7"
      },
      "outputs": [],
      "source": [
        "# Instalamos Spark para Python\n",
        "!pip install pyspark\n",
        "\n",
        "# Instalamos Java SDK 8\n",
        "import os, sys\n",
        "\n",
        "# !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "# !apt-get update\n",
        "!apt-get install -y openjdk-8-jdk -qq > /dev/null      #install openjdk\n",
        "!echo $(/usr/libexec/java_home -v 1.8)\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "!echo 2 | update-alternatives --config java\n",
        "!java -version       #check java version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI9R_2sXOFPs"
      },
      "outputs": [],
      "source": [
        "#Lo configuramos para que lea desde el Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "pwhghNY8QVE6"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "from pyspark import SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "\n",
        "input_path = '/content/drive/MyDrive/Colab/A3/input/'\n",
        "\n",
        "# Creamos el contexto de Spark\n",
        "sc = SparkContext(\"local\", \"TP3\")\n",
        "\n",
        "# Crear el StreamingContext para procesar documentos cada 10 segundos\n",
        "# Estos documentos provienen de otro entorno, donde se mueve un archivo (review) de la carpeta \"reviews\" a la carpeta de entrada \"input\" cada 10 segundos.\n",
        "# Esta configuración asegura que se procese un único documento por cada intervalo de tiempo de 10 segundos.\n",
        "ssc = StreamingContext(sc, 10)\n",
        "\n",
        "ssc.checkpoint(\"/content/drive/MyDrive/Colab/A3/buffer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk-Dy5azEnYq"
      },
      "outputs": [],
      "source": [
        "# Crear el DStream leyendo archivos de texto en el directorio\n",
        "streamOriginal = ssc.textFileStream(input_path)\n",
        "\n",
        "num_documentos = sc.accumulator(0)\n",
        "\n",
        "# Función para actualizar el estado de los términos\n",
        "def fUpdate(nuevos_valores, estado_actual):\n",
        "    tf_acumulado = 0  # Acumulador del TF\n",
        "    d_t = 0  # D(t)\n",
        "    num_documentos = 0  # #D\n",
        "\n",
        "    # Verificar si hay un estado previo para actualizar el estado actual\n",
        "    if estado_actual:\n",
        "        tf_acumulado = estado_actual[0]  # Obtener el valor acumulado del TF\n",
        "        d_t = estado_actual[1]  # Obtener el D(t) del término\n",
        "\n",
        "    # Verificar si hay nuevos valores para actualizar el estado actual\n",
        "    if nuevos_valores:\n",
        "        # Actualizar el TF acumulado sumando los nuevos valores\n",
        "        tf_acumulado += nuevos_valores[0][0]\n",
        "        # Incrementar D(t) considerando que esta funcion (fUpdate) se llama una vez por documento\n",
        "        d_t += 1\n",
        "        # Obtener la cantidad total de documentos\n",
        "        num_documentos = nuevos_valores[0][1]\n",
        "    else:\n",
        "        # Si no hay nuevos valores, se usa el estado previo para actualizar el contador de documentos\n",
        "        num_documentos = int(estado_actual[4] or 0) + 1\n",
        "\n",
        "    # Calcular el IDF del término\n",
        "    idf = log(float(num_documentos) / float(d_t)) if d_t > 0 else 0\n",
        "    # Calcular el TF-IDF del término\n",
        "    tf_idf = float(tf_acumulado) * float(idf)\n",
        "\n",
        "    # Retornar el estado actualizado del término y sus valores: TF, D(t), IDF(t), TF-IDF, #D\n",
        "    return (tf_acumulado, d_t, idf, tf_idf, num_documentos)\n",
        "\n",
        "\n",
        "# Función para calcular el TF-IDF de cada palabra por documento\n",
        "def calcular_tf_idf(documento):\n",
        "  global num_documentos\n",
        "\n",
        "  if documento.isEmpty():\n",
        "    return\n",
        "\n",
        "  # Obtener las palabras de cada documento\n",
        "  palabras_en_documento = documento.map(lambda doc: doc.split())\n",
        "\n",
        "  # Calcular la frecuencia de cada palabra por documento\n",
        "  frecuencia_palabras = palabras_en_documento.flatMap(lambda palabras: [(palabra, 1) for palabra in palabras]).reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "  # Contar la cantidad total de palabras por documento\n",
        "  total_palabras = palabras_en_documento.map(len).reduce(lambda x, y: x + y)\n",
        "\n",
        "  # Incrementar el contador de documentos\n",
        "  num_documentos.add(1)\n",
        "\n",
        "  d = num_documentos.value\n",
        "\n",
        "  # Calcular el TF de cada palabra\n",
        "  tf_y_total_documentos = frecuencia_palabras.map(lambda t: (t[0], (t[1] / total_palabras, d))) # <termino, (TF, #D)>\n",
        "\n",
        "  return tf_y_total_documentos\n",
        "\n",
        "\n",
        "# Procesamiento de los datos en streaming\n",
        "stream = streamOriginal.transform(calcular_tf_idf)\n",
        "stream.pprint()  # Mostrar resultados\n",
        "\n",
        "history = stream.updateStateByKey(fUpdate)\n",
        "history.pprint()  # Mostrar los términos y sus valores TF, D(t), IDF(t), TF-IDF, #D\n",
        "\n",
        "# Iniciar la recepción de datos y procesamiento\n",
        "ssc.start()\n",
        "ssc.awaitTermination()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "LXyR9GxsXLvx"
      },
      "outputs": [],
      "source": [
        "ssc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}